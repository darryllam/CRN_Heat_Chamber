As the project was both modular and largely virtual, large scale prototypes were not developed. The two large components of the project, the data acquisition unit and the machine learning unit, were developed concurrently with their integration being overseen as the final step. As the data acquisition unit was simple in comparison there was no need found for a preliminary design. For the software components, the design was continually iterated upon and tweaked until desired results were obtained with all iteration tracked using the revision control software Git. Therefore the preliminary software implementation in our design slowly morphed into the final design through iterating upon it. 

\subsection{Design Process of Data Acquisition}
The basic concept for data acquisition was to measure the air temperature of the curing oven as well as the internal temperature of an aluminum cylinder. The preexisting curing oven setup was used, being controlled by a PID controller being fed air temperature data using the average of four 100k NTC thermistors. \\\\
For the first design, air and internal temperature measurements were taken using five 100k NTC thermistors to ensure consistency with the original setup and to determine an accurate temperature profile for the immediate vicinity of the cylinder. The temperature data was read and logged by a Texas Instruments TM4C123G microcontroller, which was chosen due to its affordability. The cylinder was suspended by a wire cage, to maximize the thermal absorption of the cylinder. \\\\
While this setup produced data relatively consistent with what was expected, a number of issues were identified.
The biggest issue was the variance in temperature readings between the thermistors. A 3 degree difference between them was found by exposing the thermistors to a constant heat source. As the machine learning model requires accurate data to provide accurate predictions, this posed a serious issue. Possible issues were determined to be faulty connections, an incorrect circuit configuration, a wrong thermal model, and the ADC on the microcontroller. Different thermistors produced the same variance, which implied that the issue laid in the ADC of the microcontroller most likely due to a faulty board.\\\\
Another issue came from a characterization of the temperature profile in the curing oven. While the temperature on the horizontal plane was constant, there was a steep temperature gradient vertically, which entailed that the inconsistency of the wire suspension setup would make it difficult to generate reproducible data. On the other hand, the constant temperature on the horizontal plane eliminated the need for many thermistors, as only 3, for the top, middle, and bottom of the object would be necessary to determine the air temperature. 
For the final design, a Raspberry Pi 4 microcontroller was used to read and log thermistor data, as its readings were found to be consistent when exposed to constant heat. As the position of the cylinder in the chamber was found to be a significantly larger influence on temperature than the existence of other thermally conducting masses, a wooden base was used to support the cylinder rather than the wire suspension. Studs were cut into the top to isolate the cylinder. The specifics of the final design are shown in Design Details section \ref{Design_Details} of the report.
\subsection{Simulation for Data Generation}
Using machine learning algorithms to predict the soak time for a curing cycle could possibly require a large amount of data for training and testing. During the planning stages of this project, we determined that heat chamber testing may be insufficient for generating the required amount and different types of data. In addition, simulation of the process allows us to tweak and iterate on the design with different data and different amounts of data easily. Physical tests would add extra cost and time running the heat chamber, along with the difficulty of acquiring parts with different materials, various geometries and properties. \\\\
To acquire data more economically, we found that the best way to address this problem would be to implement finite element software to build a thermal model and simulate curing cycle data sets, a technique used in articles from the literature review \cite{rnn}. %MATLAB was chosen because of its built-in toolboxes and functions like the Partial Differential Equation (PDE) Toolboxâ„¢. This toolbox can be used for solving partial differential equations and FEM heat transfer problems \cite{matlab}. The PDE toolbox allows users to create a thermal model which holds the geometry, boundary temperatures, initial conditions, and material properties of the thermal system and simulate the transient response.
Using the PDE Toolbox, we were able to model our aluminum cylinder and the heat chamber conditions then simulate the transient response for the system. Generating simulated curing cycles in MATLAB produces useful data sets with similar features to real curing cycle data. These simulations are important because providing a neural network or machine learning algorithm with data sets accurately representing real data sets will increase the robustness. The resulting simulations can effectively train and test a neural network, reducing the time and money needed for experimental testing needed for generating data sets. Fundamentally the simulated data allowed us to quickly iterate and tweak the machine learning system and check its validity in predicting under different circumstances.  %Once the neural network is sufficiently trained with the simulation data, it can be used for predicting real time data sets. This is the full methodology behind this process of generating simulated data sets.

\subsection{Machine Learning Model Design Process}
Through research and experimentation, we narrowed down the algorithms we were interested in and selected two final algorithms to implement and compare. The two supervised learning techniques that we focused on were Random Forests and RNN specifically Long Short-term Memory networks (LSTM). To better understand the applicability to our problem, we continued researching these two algorithms and implemented them into our preliminary design. \\\\
The fundamental design of these models are accessed through library's and packages mentioned in the Solution Generation in section \ref{ML_platform}. Both Keras/Tensorflow and Sci-kit learn were used to implement the bulk of the learning networks which make up the machine learning algorithms. This left us with having to design the machine learning parameters, implement the surrounding code to access the packages and libraries, and then output the performance of the machine learning processes. In addition to this, there was also the task of applying code to make predictions, and show the capability as a control source for the data acquisition unit. To quickly prototype the algorithm on larger data sets, the simulated data was used. The simulated data allowed us to quickly asses the feasibility of the machine learning algorithm and quickly iterate on the design to improve it. As mentioned above, iterating on software was simple with the help of revision control software. Once real data was obtained, the machine learning algorithms proved to be well designed because of the previous work done to validate our designs on the simulated data. \\\\