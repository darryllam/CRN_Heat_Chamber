\subsection{Previous Solutions by Stakeholders}
To define the problem with the current solution, an assessment of the client’s current solution was done. The lab was using a heat chamber with an infrared (IR) lamp as the heating source for curing composites. Inside the heat chamber, three thermocouples are used to measure the air temperature. Due to variability in temperature inside the chamber and variability between the sensors themselves, an average of all the thermistors are used as the temperature which the Ardiuno acts on. This average value gives an accurate enough reading of the air temperature recorded over the entire curing run. The chamber uses a PID controller which controls the IR lamp by sending a PWM signal to a MOSFET. The heat chamber’s temperature rises a few degrees per minute until the desired curing temperature is reached. As specified earlier, the heat transfer characteristics of a composite part are not easily determined, and therefore the soak time cannot be analytically determined. The method currently used is to hold a part at the target temperature for a period of time determined heuristically. This time is long to ensure the part temperature reaches the threshold and is cured completely. This is where the current solution needed improvement because the minimum soak time required for the part to reach equilibrium temperature was being exceeded. Because of this, the heat chamber was being used longer than necessary which led to wasted time and power.

\subsection{Industry Solutions}
When initially formulating solutions to the problem, a literature review was done to assess current industry solutions for accurately predicting part temperature and estimating soak time. This section reviews current industry solutions for optimizing composite curing and evaluates their potential application to this project. \\\\
It was found the key parameters involved in the cure cycle are the heat transfer characteristics, material properties, heat convection through the material, and surrounding air temperature. In the composites manufacturing industry, using control strategies and numerical simulations is a technique for developing an optimal cure cycle. The numerical simulations involve adjusting parameters previously mentioned to build prediction models for improving the degree of cure and minimizing the total time of cure. By defining boundary conditions inside the heating chamber, finding an energy equation combined with a kinetic model, and using finite element software, the degree of cure and temperature across a composite can be simulated \cite{curesim}.  Here the numerical simulations showed the degree of cure and temperature at various points on the composite with different thicknesses. The paper however did not have experimental data of an actual cure cycle to compare with the simulation results. This process can be validated as seen in \cite{polylam} which used similar numerical simulations and had results showing accurate estimates of part temperature and better degree of cure at various points on the composite. The solutions proposed in these studies struggle to address the problem of producing a non-uniform temperature distribution across composite materials. This causes some spots on the composite to be burnt and others processed below the desired temperature. Also, the models still cannot always accurately predict the soak time.\\\\
Another possible solution was a self-tuning method used for finding the optimal curing parameters using a programmable microcontroller to create a self-tuning algorithm \cite{selftune}. First, the oven parameters were used to create an electrical model and then derive a differential equation which could be used for finding an optimal cure cycle. A PID controller was implemented to adjust the oven temperature based on the differential equation and electrical model. Finally, simulation results were compared with experimental results to prove the self-tuning method’s accuracy. The results of this study reveal similar problems found with our clients curing process, such as the inability to fully predict when the part is within the desired curing temperature. The solution also does not provide the level of innovation we hoped to achieve in this project.

\subsection{Machine Learning Applications in Composite Curing}
For this project it was desirable to implement an Industry 4.0 design as a solution, and specifically an Artificial Neural Network (ANN). The motivation behind this decision was supported by evidence from literature on applying an ANN to composites curing. It was also found that the problems associated with the other current solutions discussed earlier can be mitigated using an ANN, from sources such as ’Prediction and optimization of cure cycle of thick fiber-reinforced composite parts using dynamic artificial neural networks’ \cite{ann}. This study implemented a neural network with the purpose of optimizing cure cycles using the surrounding air temperature and the characteristics of the composite. This goal is achieved by first building a finite element model (FEM) on the composite part. The FEM provided sample data of the variables time, autoclave temperature, and composite part temperature at specific points. Then this data was used for both training and testing two different neural networks. One network was used to model the output and control of the composite’s temperature and the other for the composite’s degree of cure. Doing this allowed them to see relationships between a part’s temperature and the degree of cure at various points on the part. The study then looked at several different training algorithms and found Bayesian Regularization had the strongest prediction ability. Also, it was found that making changes to the ANN architecture like changing the number of neurons had no significant changes to the predicted output. Overall, the ANN applied in showed results that reduced soak time and accurately monitored a given part’s internal temperature.\\\\
Then in ‘Optimization of the Temperature-Time Curve for the Curing Process of Thermoset Matrix Composites’ \cite{rnn} it showed a recurrent neural network (RNN) which is a specific type of ANN. This was applied towards optimizing cure cycles and producing a uniform cure on fiber-reinforced thermoset matrix composites. The RNN used two hidden layers between the input and output layers which allowed for increased prediction ability without adding significant amounts of time to train the network. This structure also allowed the number of neurons to be decreased because the additional hidden layer’s outputs are fed back into the network. As before, there were two RNN’s used, one for predicting the composite’s temperature and one for the degree of cure. The results produced by the RNN’s showed the optimal curing times for a composite which achieved a uniform degree of cure across the material. These results are relevant to our project because having a solution that achieves a uniform cure across a material is important to the client. These papers use epoxy parts with complex properties which are outside the scope of this project. However, the concept of training an RNN with data generated from a FEM is still useful for this project.

\subsection{Project Workflow}
To facilitate the solution generation process, a project workflow was developed. While this project was focused on designing for a specific task, the overall goal was to develop a generic workflow for applying Industry 4.0 principles to composite manufacturing processes. The workflow was generated at the start of the concept generation part of our design, allowing other solutions to fit in with each of these points. The abstracted workflow for the project was developed as follows:
\begin{enumerate}
\item Identify all input and output parameters of process
\item Use Industry 4.0 technology to automate data collection of input and output parameters
\item Process input and output data into supervised learning data sets, in which each set of inputs is mapped to one output
\item Determine models most applicable to current problem and eliminate others 
\item Design machine learning models to take input parameters and produce output parameters
\item Train ML models using collected supervised learning data set
\item Determine models that are working well with data set and eliminate others
\item Refine model parameters to enhance predictive accuracy
\item Validate model with test cases, including fringe examples
\item Integrate machine learning module into data collection network
\end{enumerate}
\subsection{Machine Learning Model Selection}
Machine learning algorithms can be categorized into four main types: supervised learning, unsupervised learning, semi-supervised learning, and reinforcement learning. In supervised learning, the algorithm takes training data and generates a function made up of biases and weights that relates the input features to the output labels of the data sample. The goal of supervised learning is to train the algorithm on known data in order to later predict on unknown data. In unsupervised learning, the algorithm does not have access to the output labels. In this case, the goal of the algorithm is to model the structure or distribution of the training data in order to later predict on unknown data. Semi-supervised learning can be considered part supervised learning and part unsupervised learning. In this case, the data contains some output labels, but output labels are not present in all of the data. In reinforcement learning, like unsupervised learning there are no output labels to train the algorithm. Rather than trying to model the structure or distribution of the data, reinforcement learning uses an agent that learns through experience and tries to maximize reward which is defined by a reward function.\\\\

Additionally in machine learning, there are two main categories of tasks: regression and classification. In regression tasks, the output label being predicted is numerical while in classification tasks, the output label is a category. In our case, the problem of finding the internal temperature of an object is a regression task.\\\\
Supervised learning was selected as the most suitable machine learning domain for our use case, as it is difficult to determine the optimal machine learning algorithm for an application without testing and comparing the results. Selection of models was also aided by the structure of inputs and outputs. Machine learning models that work well with time series data and output a real number should be prioritized. %In this manner, broad classes of machine learning were able to removed, %such as regressions due to their inputs, and classification models due to their output. \\\\

\subsubsection{Machine Learning Development Platform Selection} \label{ML_platform}
As part of our concept generation we had to decide how to implement the machine learning models described. There are many possible languages and packages which can implement these algorithms. Two languages which our group was both familiar with and had well-documented libraries were Python and MATLAB. Python was chosen due to the packages available, flexibility, experience of our group members, and preference.
\paragraph{Keras and Tensorflow} \, \\
Tensorflow is an open-source library for numerical computation and large-scale machine learning. Keras is used as a high-level neural network API for Tensorflow. Keras was chosen for this project due to its accessibility in implementing machine learning algorithms using Tensorflow. With Keras, we were able to implement the various RNN model types, such as LSTM and GRU, using Python. Using these tools, we were able to train and run the RNNs from the data gathered to accomplish our project needs.

\paragraph{Scikit-Learn}\, \\
Scikit-Learn is a machine learning library for Python. Scikit-Learn was used for this project due to its simplicity in implementing the Random Forests machine learning algorithm. It also enabled us to remain consistent with using Python for all our implementations of the machine learning methods.  
\subsection{Simulation Tools}
MATLAB was chosen because of its built-in toolboxes and functions like the Partial Differential Equation (PDE) Toolbox™. This toolbox can be used for solving partial differential equations and FEM heat transfer problems \cite{matlab}. The PDE toolbox allows users to create a thermal model which holds the geometry, boundary temperatures, initial conditions, and material properties of the thermal system and simulate the transient response. Furthermore, the entirety of the group was familiar with MATLAB. This provided a basis to get into the complex field of heat simulation while focusing on more pertinent problems.